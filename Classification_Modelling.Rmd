

```{r}
library(tidyverse)
library(tidymodels)
```


# Read in a CSV file
```{r}
df_raw <- read_csv("data/train.csv")
```

# Covert to a dataframe or tibble
# Facorize target variable

```{r}
df <- as_tibble(df_raw) 
df$Cover_Type<- as_factor(df$Cover_Type)
df <- df %>% rename(target = Cover_Type ) %>% select(target, everything())
```




# Rename Target variable - Requires tibble/df as input

## Figure out why this function does not work - Initial idea: Tidyverse function "pull out a different data structure that using $ notation (e.g. df$)


```{r}
rename_target <- function(data, target_variable) {
  data %>% select(target_variable, everything())
  
}


```


# S3 method for workflow
tune_grid(
  object,      # workflow object
  resamples,   # rsamples object
  ...,
  param_info = NULL,  # dials:parameters object
  grid = 10, # dataframe of tuning values
  metrics = NULL,  # yardstick:metric_set()
  control = control_grid() # object for modifying the tuning process
)

# Control_grid object

control_grid(
  verbose = FALSE,
  allow_par = TRUE,
  extract = NULL,
  save_pred = FALSE,
  pkgs = NULL,
  save_workflow = FALSE,
  event_level = "first",
  parallel_over = NULL
)


# S3 method for workflow
tune_bayes(
  object,
  resamples,
  ...,
  iter = 10,
  param_info = NULL,
  metrics = NULL,
  objective = exp_improve(),
  initial = 5,
  control = control_bayes()
)







Create stratified k-fold cross validation 
```{r}
set.seed(23)

df <- df %>% sample_frac() # Shuffle the rows

split_df <- df %>% initial_split()

train_df <- training(split_df)

test_df <- testing(split_df)

set.seed(21)


#Notes
#This data does not require stratiefied resampling - otherwise add the parameter for strata (default strata = NULL)
# The split into k-folds is only done for the training data set and not for the testing data set

fold_df <- vfold_cv(train_df, v= 5)


```



Pre-processing steps

#Impute
#Handle factor levels
#Individual transformations for skewness and other issues
#Discretize (if needed and if you have no other choice)
#Create dummy variables
#Create interactions
#Normalization steps (center, scale, range, etc)
#Multivariate transformation (e.g. PCA, spatial sign, etc)


```{r}
# no missing 
# The recipe function is applied to the complete training fold and not the k-fold data structure - Check other examples


# Starting recipe for a Random Forest Model
recipe_rf <- recipe(target ~ ., data = train_df) %>% step_nzv(all_predictors()) %>% step_normalize(all_predictors()) %>% step_corr(all_predictors())

prep_recipe <- prep(recipe_rf, training = train_df,
                      strings_as_factors = FALSE)
# Print out prepped recipe to control the pre-processing steps
prep_recipe

```




# Define evaulation metric

```{r}
eval_metric <- metric_set(accuracy)


```


# Define ctrl grids

```{r}
# grid specification based on the example of rf with mtry and min_n as tune parameters
rf_params <- parameters(finalize(mtry(), select(df, -target)) , min_n())



rf_grid <- grid_max_entropy(rf_params, size = 20)


head(rf_grid)


# Check the use of these functions later
#ctrl_grid <- control_grid()
#ctrl_res <- control_resamples()
```

# Define models

```{r}

# Linear regression model

lin_reg_mod <-
  linear_reg(
   penalty=tune(),
   mixture=tune()
  ) %>%
  set_engine("lm")

#Regularized linear regression


# Random forest model
rf_mod <- rand_forest(
  mtry = tune(),
  trees = 1000,
  min_n = tune()
) %>%
  set_mode("classification") %>%
  set_engine("ranger")

# Binary regression model

Log_class <- logistic_reg(
  penalty=tune(),
  mixture=tune(),
) %>% set_engine("glmnet")


# XGboost model/Boosted trees

boost_mod <- boost_tree(
  mtry= tune(),
  tree=tune(),
  learn_rate = tune(),
  tree_depth = tune()
  ) %>% set_engine("xgboost") %>%
  set_mode("classification") # Otherwise regression


# Support Vector model for classification

svm_mod <-
  svm_rbf(mode = "classification", cost = tune(), rbf_sigma = tune()) %>%
  set_engine("kernlab")

```



#Define workflow

```{r}
tune_wf <- workflow() %>% add_recipe(recipe_rf) %>% add_model(rf_mod)

```

#Define the control grid - keep predictions and print out progress
```{r}
ctrl_features <- control_grid(verbose = TRUE, save_pred = TRUE)

```



# Fit the model/workflow

```{r}
doParallel::registerDoParallel()

set.seed(135)


start_time <- Sys.time()


tune_res <- tune_grid(
  tune_wf,
  resamples = fold_df,
  grid = 20,
  control = ctrl_features
  
  
)

end_time <- Sys.time()


tune_res

total_time <- end_time - start_time


```


# Select the best combination of tuning-factors
# You have to define the loss/optimization criteria to select the best parameter combination
# Comment - Look up the process for using custom metrics

```{r}
best_params <- tune_res %>% select_best("accuarcy")
```

# Finalize the model
# The function takes as an input the workflow object(model + recipe/pre-processed training data)
```{r}
final_wf <- tune_wf %>% finalize_workflow(best_params)


```

#Fit the final workflow to the whole data set - Dataframe which is assigned to the initial_split function
# Comment - Understand better which data set should be used in the last fit call
```{r}
final_fit_rf <- final_wf %>% last_fit(split_df)
```


```{r}
final_fit_rf %>%
  collect_metrics()


final_fit %>%
  collect_predictions() %>% 
  roc_curve(class, .pred_PS) %>% 
  autoplot()
```








